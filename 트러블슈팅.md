
### debezium
Msa 로 진행하며 서비스간 의존도를 낮추기 위해 데이터베이스도 독립적으로 설계하고 카프카를 통해 데이터 동기화를 진행하였습니다
그런데 카프카 커넥터 모드에는 increment bulk timestamp 가 있었으며 수정 삭제 이벤트에 반응이 안되고
bulk 는 너무 오버헤드라는 느낌이 들어 debezium 을 찾게 되었습니다

io.debezium.DebeziumException: Encountered change event for table mungmomember.oauth_login whose schema isn't known to this connector
history.bat 에서 데이터베이스 이름이 mungmoMember 로 되어 있었는데,
이벤트는 데이터베이스 이름을 소문자로 인식하기에 매칭이 안되었던 것이다.
이러한 오류가 다른 곳에서 발생할 수 있는 것이기에 데이터베이스 자체도 소문자로 구성하고, 모든 세팅을 소문자로 진행하였다.

### 카프카를 이용한 채팅 서비스
환경 : Jmeter(유저 200, 1초에 20번 메세지 발행), kafka(topic : 파티션 3), m2 mem:16g
처음 카프카를 통해 채팅서비스를 만들었을 땐, 많은 자료가 더 많은 tps 감당할 수 있을거라했다.
첫번째는 그 말을 믿고 진행했고 두번째는 어차피 컨슘에 들어와 로직처리하는건 스프링인데 과연 맞을까 생각했다.
결론은 200명 유저가 1초에 20번 메세지 발행 조건으로 미세한 차이로 더 낮은 tps를 보였다.
카프카 이용 시, 180/s 미사용 시, 187/s
카프카를 사용한다는 오버헤드로 인해 처리 속도가 조금 더 낮다는 결론이 났다.
다른 사람들은 왜 그런 글을 올렸을까.. 도저히 이해가 되지않아 알아보니, 이력서용으로 자작극을 한 것이였다.
그렇다면 채팅서비스를 구현하는데 카프카가 필요한 이유는 비동기 분산처리로 유용한 것 보다 디커플링인 것으로 현재는 결론을 지었다.



























