[kafka 데이터베이스 동기화](#kafka)
[실시간 데이터 변경](#실시간-데이터-변경)
[24시 동물병원](#24시-동물병원공공데이터)
[알림](#알림)

### kafka

Kafka 사용 이유, EDA(Event-Driven Architecture)
핵심 비동기, 분산처리, 스트리밍

서비스 간의 통신
기존에는 RestApi 통신으로, 커플링되어 응답 서버에 문제가 있으면 요청한 서버에서 진행이 안되기에 디커플링이 필요하다.
(MSA 의 의존성 낮추는 장점이 무너짐)
I/O 데이터 구조 변경이 어려움
(연결되는 서비스가 모두 다 같이 변경 해야한다.)
부하분산 필요
메시지 큐(Rabbit MQ, Active MQ)
메모리에서 관리하고 반환하면 기존 데이터를 삭제한다.(여러 서비스에 전송 불가)
낮은 처리량(through put)
높은 레이턴시(latency)
그래서 이벤트 기반 MSA 아키텍쳐 Apache kafka 사용

rest api vs kafka cdc
핵심 데이터 정합성
REST API 호출이 적합한 경우:
실시간 데이터 접근이 필요할 때
동기적 처리와 강한 일관성이 필요할 때
이벤트 기반 통신이 적합한 경우:
비동기적 처리가 가능하고 일관성 요구가 낮을 때
서비스 간의 결합도를 낮추고 확장성을 높이고 싶을 때

ZooKeeper Cluster 기본 구성
ZooKeeper Service 는 “Ensemble” 이라고 불리는 Host 들의 집합들을 통해서 복제되며,
동일한 어플리케이션을 구성하는 서버들의 복제된 그룹을 “Quorum” 이라고 부른다.
Quorum 내의 모든 서버는 동일한 설정 파일들의 복제본을 가지고 있다.
ZooKepper의 서버 구성의 수는 절반이 실패해도 기능을 수행할 수 있도록 항상 홀수로 구성하는 것을 권장한다.
예를 들어 2대의 서버가 장애 상태가 되어도 나머지 서버들이 동작할 수 있도록 5대의 서버로 구성하는 것이다.
이 중에 한 대는 Leader가 된다. 최소한의 구성은 3 대가 된다.
참조 : https://yooloo.tistory.com/102

connect mode 로 incrementing 를 사용한 결과, 수정을 감지못하는 상황을 확인하였다.
kafka connect mode
bulk : 데이터를 폴링할 때 마다 전체 테이블을 복사
incrementing : 특정 컬럼의 중가분만 감지되며, 기존 행의 수정과 삭제는 감지되지 않음
timestamp : timestamp형 컬럼일 경우, 새 행과 수정된 행을 감지함

벌크는 모든 데이터 삭제, 삽입이 오버헤드로 느껴지고, 타임스탬프는 모든 테이블에 컬럼을 추가하고, 수정 시 같이 변경해줘야한다는 것이 부담이 되었다.

cdc 도구로 Debezium 를 사용하기로 하였다.


==========================================================================================

### 실시간 데이터 변경

- 동네인증
한달에 한번 재인증을 처음에 스케줄러를 생각했지만 카프카의 실시간을 이용할 수 있을거라 생각했고 카프카 스프림즈를 찾았다.

Kafka Streams 는 Stream API 로 구축된 애플리케이션이고, 브로커와 별도로 구성된다.
// Stream API : 컬렉션, 배열등의 저장 요소를 하나씩 참조하며 함수형 인터페이스(람다식)를 적용하며 반복적으로 처리할 수 있도록 해주는 기능
kafka 내부에서 메시지 파이프라인을 구성한다고 생각할 수 있다.
따라서 브로커의 특정 토픽을 구독하여 일련의 로직을 처리한 뒤에, 다시 다른 토픽으로 publish 한다.
쉽게 말하면 kafka 내부에 있는 데이터에 가공처리한 후 다시 다른 토픽이나 같은 토픽으로 넣어주는 역할을 한다.
Kafka streams 는 라이브러리로 제공되기 때문에 단순히 main 함수 내에서도 구현이 가능하고, 특정한 프레임워크에 종속되지 않을 수 있다.
Kafka streams 는 java 와 scala 언어를 지원하고 있다.
참조 : https://jackcokebb.tistory.com/9

Kafka streams 구현방식(Stream DSL, Processor API)

1. Stream DSL (Domain Specific Language)는 Stream Processor API를 사용해서 구현되어 있다.
    이 방식은 미리 제공되는 함수들을 이용해서 토폴로지를 정의하는 방식이다. 
    이 방식은 스트림과 테이블에 대한 추상화(KStream, KTable, GlobalKTable)를 제공하고, 
    선언적인 함수형 스타일의 stateless transformantion을 제공한다(map, filter 등). 
    뿐만 아니라 stateful transformation을 제공한다. 
    (aggregation, join, windowing) 따라서 이 방식은 Processor API보다 비교적 추상적이고 사용하기가 쉽다.
    //stateful transformation:  Streams가 작동할때 상태값을 저장한다는 것이다. 즉 n번째 상태값이 n+1번째 결과값에 영향을 미친다는 것이다

2. Processor API 은 정의된 함수를 사용하지 않고 직접 구현해야 한다.
    구현하기에는 어렵지만 그만큼 정교한 로직을 짤 수 있다.
    Processor API를 통해서 임의의 스트림 프로세서를 정의할 수 있으며
    Processor API는 Stateless, Stateful 오퍼레이션을 구현하기 위해 사용될 수 있다.
    (이 프로세서를 관련된 State Store와 연관시켜 Processor Topology를 구성할 수 있다.)


==========================================================================================

### 24시 동물병원(공공데이터)



==========================================================================================

### 알림
처음에 SSE 로 알림을 개발을 생각했다
하지만 앱을 종료하였을 경우, 통신이 끊기기에 핸드폰 알림이 울리지 않을 것이라는 생각이 들었다.

찾아보니 Firebase Cloud Messaging (FCM)을 사용하여 알림 기능을 구현할 수 있었다.
안드로이드 IOS 둘다 사용이 가능한 부분이어서 따로 구현해야한다는 고민을 덜할 수 있게 되었다.

Firebase 콘솔에서 직접 생성하기: (serviceAccountKey.json)
Firebase 콘솔(https://console.firebase.google.com/)에 접속합니다.
프로젝트를 선택하고, 왼쪽 메뉴에서 "프로젝트 설정"으로 이동합니다.
"서비스 계정" 탭을 선택하고, "새 비공개 키 생성" 버튼을 클릭합니다.
JSON 형식으로 키를 생성하고 파일을 다운로드 받습니다.


















